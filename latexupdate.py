import tensorflow as tf
import tensorflow.keras as keras
import numpy as np
import cv2
import pytesseract
from transformers import pipeline
import torch
from ultralytics import YOLO

class AdvancedMathOCR:
    def __init__(self):
        # M√¥ h√¨nh nh·∫≠n d·∫°ng v√πng to√°n h·ªçc
        self.yolo_detector = self.load_yolo_model()
        
        # M√¥ h√¨nh CNN chuy√™n to√°n
        self.math_cnn = self.build_math_cnn()
        
        # M√¥ h√¨nh transformer
        self.transformer_model = self.load_transformer_model()
        
        # M√¥ h√¨nh x·ª≠ l√Ω h√¨nh h·ªçc
        self.geometry_model = self.build_geometry_model()
    
    def load_yolo_model(self):
        """T·∫£i m√¥ h√¨nh YOLO ƒë·ªÉ detect v√πng to√°n h·ªçc"""
        model = YOLO('yolov8_math_detection.pt')
        return model
    
    def build_math_cnn(self):
        """X√¢y d·ª±ng m√¥ h√¨nh CNN chuy√™n bi·ªát to√°n h·ªçc"""
        model = keras.Sequential([
            keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),
            keras.layers.MaxPooling2D((2, 2)),
            keras.layers.Conv2D(64, (3, 3), activation='relu'),
            keras.layers.MaxPooling2D((2, 2)),
            keras.layers.Conv2D(64, (3, 3), activation='relu'),
            keras.layers.Flatten(),
            keras.layers.Dense(64, activation='relu'),
            keras.layers.Dense(10, activation='softmax')
        ])
        model.compile(optimizer='adam', 
                      loss='categorical_crossentropy', 
                      metrics=['accuracy'])
        return model
    
    def load_transformer_model(self):
        """T·∫£i m√¥ h√¨nh transformer cho chuy·ªÉn ƒë·ªïi LaTeX"""
        model = pipeline('text-to-text', 
                         model='facebook/math-mathbert')
        return model
    
    def build_geometry_model(self):
        """M√¥ h√¨nh chuy√™n v·ªÅ x·ª≠ l√Ω to√°n h√¨nh h·ªçc"""
        model = keras.Sequential([
            keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),
            keras.layers.MaxPooling2D((2, 2)),
            keras.layers.Conv2D(64, (3, 3), activation='relu'),
            keras.layers.GlobalAveragePooling2D(),
            keras.layers.Dense(128, activation='relu'),
            keras.layers.Dense(5, activation='softmax')  # 5 lo·∫°i h√¨nh h·ªçc c∆° b·∫£n
        ])
        return model
    
    def preprocess_image(self, image_path):
        """Ti·ªÅn x·ª≠ l√Ω ·∫£nh t·ªëi ∆∞u"""
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        image = cv2.resize(image, (224, 224))
        image = image / 255.0  # Chu·∫©n h√≥a
        return image
    
    def detect_math_regions(self, image_path):
        """Ph√°t hi·ªán v√πng to√°n h·ªçc"""
        results = self.yolo_detector(image_path)
        return results
    
    def ocr_extraction(self, image_path):
        """Tr√≠ch xu·∫•t vƒÉn b·∫£n b·∫±ng Tesseract"""
        text = pytesseract.image_to_string(image_path)
        return text
    
    def convert_to_latex(self, text):
        """Chuy·ªÉn ƒë·ªïi sang LaTeX"""
        latex_output = self.transformer_model(text)[0]['generated_text']
        return latex_output
    
    def ensemble_prediction(self, image_path):
        """K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh"""
        # Ph√°t hi·ªán v√πng
        regions = self.detect_math_regions(image_path)
        
        # X·ª≠ l√Ω t·ª´ng v√πng
        results = []
        for region in regions:
            # C·∫Øt v√† x·ª≠ l√Ω t·ª´ng v√πng
            cropped_image = self.preprocess_image(region)
            
            # CNN nh·∫≠n d·∫°ng
            cnn_pred = self.math_cnn.predict(np.expand_dims(cropped_image, 0))
            
            # OCR tr√≠ch xu·∫•t
            ocr_text = self.ocr_extraction(region)
            
            # Chuy·ªÉn LaTeX
            latex_result = self.convert_to_latex(ocr_text)
            
            results.append({
                'region': region,
                'cnn_prediction': cnn_pred,
                'ocr_text': ocr_text,
                'latex': latex_result
            })
        
        return results
    
    def render_streamlit_ui(self):
        """Giao di·ªán ng∆∞·ªùi d√πng"""
        import streamlit as st
        
        st.title("üßÆ H·ªá Th·ªëng OCR To√°n H·ªçc Th√¥ng Minh")
        
        uploaded_file = st.file_uploader("T·∫£i ·∫£nh to√°n h·ªçc", 
                                         type=['png', 'jpg', 'jpeg'])
        
        if uploaded_file:
            # L∆∞u ·∫£nh
            with open("temp_math_image.png", "wb") as f:
                f.write(uploaded_file.getbuffer())
            
            # Ph√¢n t√≠ch
            results = self.ensemble_prediction("temp_math_image.png")
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            for idx, result in enumerate(results, 1):
                st.subheader(f"V√πng To√°n H·ªçc {idx}")
                st.write("VƒÉn B·∫£n OCR:", result['ocr_text'])
                st.write("LaTeX:", result['latex'])
                st.write("ƒê·ªô Ch√≠nh X√°c CNN:", result['cnn_prediction'])

# Hu·∫•n luy·ªán m√¥ h√¨nh
def train_models():
    # Logic hu·∫•n luy·ªán c√°c m√¥ h√¨nh
    pass

if __name__ == "__main__":
    math_ocr = AdvancedMathOCR()
    math_ocr.render_streamlit_ui()
